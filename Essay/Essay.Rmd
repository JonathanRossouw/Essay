---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Comparing SVR to LSTM ANN for Volatility Forecasting"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Jonathan Rossouw"  # First Author - note the thanks message displayed as an italic footnote of first page.
#Ref1: "Prescient Securities, Cape Town, South Africa" # First Author's Affiliation
Email1: "20858345\\@sun.ac.za" # First Author's Email address

#Author2: "John Smith"
#Ref2: "Some other Institution, Cape Town, South Africa"
#Email2: "John\\@gmail.com"
#CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

#Author3: "John Doe"
#Email3: "Joe\\@gmail.com"

#CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
#keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
#BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
#addtoprule: TRUE
#addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
#Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  Volatility modelling is an important problem in financial econmetrics. The recent prolierfation of powerful machine learning techniques offers a models that are well suited to this complex problem. In this paper volatility forecasting by Support Vector Regression (SVR) and Long-Short Term Memory Recurrent Neural Networks (LSTM) are compared. The JSE All Share index is used to compare. An EGARCH models is used as a baseline model. The LSTM model performed best at one-day ahead and three-day ahead forecasting. 
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
pacman::p_load(rugarch, cowplot, tbl2xts, fmxdat, ggplot2, sugrrants, kableExtra, rsample, glue, tictoc)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% .[!grepl('Old_code', .)] %>% as.list() %>% walk(~source(.))

# Set whether cached hyperparameter tuning results are used
cache <- TRUE
```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

Volatility modelling is an important and complex problem in financial econometrics. The volatility the returns of an asset are an important measure for the risk of an asset. Volatility itself is a key factor in options pricing and in asset allocation. The Value-at-Risk calculations made for risk management rely on measures of volatility. There has been a recent proliferation of machine learning techniques that can greatly improve the precision of volatility forecasting. The traditional forecasting techniques build on the generalized autoregressive conditional heteroscedastic (GARCH) class of models are well suited for uncovering the true patterns of volatility. However, their ability to accurately forecast volatility is limited. \par
The use of machine learning techniques including Support Vector Regression (SVR) and artifical neural network models has grown in recent years with far superior performance (citation needed). Recently proposed volatility models using the long-short term memeroy recurrent neural network (LSTM) have futher improved forecasting precision(citation needed). While these models have been used to model volatility in the US, only the SVR and GARCH models have been applied to South African data. \par
The volatility of the JSE ALSI total returns index (TRI) is modelled. This paper finds that the GARCH models perform poorly on pure forecasting precision. The SVR and LSTM models perform similarly well on one-day ahead forecasting with the LSTM marginally better. On three-day ahead forecasting 


The remainder of the paper is organised as follows: the data and methodology is described, the results are analysed followed by the conclusion.

# Data  {-}

The data used in this paper is the total return index (TRI) of the JSE ALSI. The TRI is price adjusted for dividends, stock splits and other corporate actions. The data is split into training, validation and test series. The training set is from 05-01-2009 to 30-12-2016, the validation set is from 03-01-2017 to 31-12-2018, and the test set is from 03-01-2019 to 31-12-2019. Returns, dlogret, are calculated using log difference of TRI, log(TRI) - log(lag(TRI)). The volatility, sigma, is calculated as dlogret^2.

#  Methodology \label{Meth}

# Results

```{r split, message=FALSE, warning=FALSE}
data <- fmxdat::Jalshtr

# Wranlge Data and Create data sets
data_train <- data_wrangling_func(data = data, start_date = "2009-01-01", final_date = "2017-01-01")
  
data_val <- data_wrangling_func(data = data, start_date = "2017-01-01", final_date = "2019-01-01")

data_test <- data_wrangling_func(data = data, start_date = "2019-01-01", final_date ="2020-01-01")

# Create Min-Max Scaled Data Sets

data_train_scaled <- data_wrangling_func(data = data, 
                                  start_date = "2009-01-01", 
                                  final_date = "2017-01-01", 
                                  type = "scaled")
  
data_val_scaled <- data_wrangling_func(data = data, 
                                start_date = "2017-01-01", 
                                final_date = "2019-01-01", 
                                type = "scaled")

data_train_full_scaled <- data_wrangling_func(data = data, 
                                start_date = "2009-01-01", 
                                final_date = "2019-01-01", 
                                type = "scaled")

data_test_scaled <- data_wrangling_func(data = data, 
                                 start_date = "2019-01-01", 
                                 final_date ="2020-01-01", 
                                type = "scaled")

```

```{r garch}

# Test for GARCH effects
cond_het <- test_cond_het_func(data_train)
cond_het

# Find best model
best_mod <- vol_select_func(data_train)
best_mod

# Train

# Fit Model
garch_fit <- vol_func(data_train, "eGARCH")
# Model Coefficients
garch_fit@fit$matcoef

# Plot Model
garch_train_plot <- vol_plot_func(data = data_train_scaled, 
              fit = sigma(garch_fit) %>% xts_tbl()%>% 
                rename(sigma = coredata.xts.) %>% 
                mutate(date = as.Date(date)) %>% 
                mutate(sigma = (sigma - min(data_train$y))/(max(data_train$y) - min(data_train$y))/100),
              title = "Comparison: Returns Sigma vs Sigma from Garch")

# Val

# Fit Model
garch_fit_val <- vol_func(data_val, "eGARCH")
# Model Coefficients
garch_fit_val@fit$matcoef

# Plot Model
garch_val_plot <- vol_plot_func(data = data_val_scaled, 
              fit = sigma(garch_fit_val) %>% xts_tbl()%>% 
                rename(sigma = coredata.xts.) %>% 
                mutate(date = as.Date(date)) %>% 
                mutate(sigma = (sigma - min(data_val$y))/(max(data_val$y) - min(data_val$y))/100),
              title = "Comparison: Returns Sigma vs Sigma from Garch")
```

```{r lstm}

pacman::p_load(reticulate)

reticulate::use_virtualenv("/Users/jonathanrossouw/Desktop/Masters/Dat Sci/ML/Project/.venv", require = TRUE)
# reticulate::py_config()
# Install Tensorflow and Keras in virtual environment
### virtualenv_install(".venv/", "tensorflow")
### install_tensorflow()
### install_keras()
# Load Tensorflow and Keras
library(tensorflow)
library(keras)

```

```{r create-arrays}
### Create LSTM Data Arrays
data_lstm_lists <- data_array_func(data = data_train_scaled, 
                              val = data_val_scaled,
                              initial = 1, 
                              assess = 1, 
                              skip = 0, 
                              type = "one_day")

```

```{r lstm_one_day, message=FALSE}
#### Fit the best univariate LSTM according to the results of 
# the hyperparameter tuning
if(!cache){
  tic()
lstm_fit <- hyp_tune_func(data_lists = data_lstm_lists,
                         data_actual = data_val_scaled %>% tail(-1), 
                         hyperparams = lstm_hyp, 
                         fit_func = lstm_fit_func,
                         type = "lstm")
toc()
write.csv(lstm_fit, "cache/lstm_tune")
}

if(cache){
  lstm_fit <- read.csv("cache/lstm_tune", row.names = 1) %>% as_tibble()
}

best_lstm_tune <- lstm_fit %>%  
  filter(mse == min(mse))

lstm_perf <- perf_plot(data_lists = data_lstm_lists,
                       data_val = data_val_scaled %>% tail(-1), 
                       data_train = data_train_scaled %>% tail(-1),
                       hyperparams = best_lstm_tune,
                       fit_func = lstm_fit_func,
                       type = "lstm",
                       train_title = "LSTM One-Day Ahead Train Plot",
                       val_title = "LSTM One-Day Ahead Validation Plot")

lstm_perf$training_error$mse

lstm_perf$performance$mse
```

```{r plot_val, fig.align='center', fig.cap="LSTM One-Day Ahead Validation Forecast"}
lstm_perf$val_plot
```

```{r create-arrays_3}
### Create LSTM Data Arrays
data_lstm_lists_3 <- data_array_func(data = data_train_scaled, 
                              val = data_val_scaled,
                              initial = 2,
                              assess = 1,
                              skip = 0, 
                              type = "three_day")
```

```{r lstm_3}
#### Fit the best univariate LSTM according to the results of 
# the hyperparameter tuning
if(!cache){
  tic()
lstm_fit_3 <- hyp_tune_func(data_lists = data_lstm_lists_3,
                         data_actual = data_val_scaled %>% tail(-4), 
                         hyperparams = lstm_hyp_3, 
                         fit_func = lstm_fit_func,
                         type = "lstm")
write.csv(lstm_fit, "cache/lstm_tune_3")
toc()
}

if(cache){
  lstm_fit_3 <- read.csv("cache/lstm_tune_3", row.names = 1) %>% as_tibble()
}

best_lstm_tune_3 <- lstm_fit_3 %>%  
  filter(mse == min(mse))

lstm_perf_3 <- perf_plot(data_lists = data_lstm_lists_3,
                         data_train = data_train_scaled %>% tail(-4),
                         data_val = data_val_scaled %>% tail(-4), 
                       hyperparams = best_lstm_tune_3,
                       fit_func = lstm_fit_func,
                       type = "lstm",
                       train_title = "LSTMThree-Day Ahead Train Plot",
                       val_title = "LSTM Three-Day Ahead Validation Plot")


lstm_perf_3$training_error$mse

lstm_perf_3$performance$mse
```


```{r svr_data}

library(liquidSVM)

## One Day Forecast
# Create list of training and validation sets

data_svr_array <- data_array_func(data = data_train_scaled,
                                  val = data_val_scaled,
                                  initial = 1,
                                  assess = 1,
                                  skip = 0, 
                                  type = "one_day")

data_svr_lists <- data_svr_wrangle(data_array = data_svr_array)
```

```{r svr_eval_perf}

if(!cache){
  tic()
  svr_fit <- hyp_tune_func(data_lists = data_svr_lists,
                         data_actual = data_val_scaled %>% tail(-1),
                         hyperparams = svr_hyp,
                         fit_func = svr_fit_func, 
                         type = "svr")
  write.csv(svr_fit, "cache/svr_tune")
  toc()
}

if(cache){
  svr_fit <- read.csv("cache/svr_tune", row.names = 1) %>% as_tibble()
}

# Best hyperparameters

best_tune_svr <- svr_fit %>% filter(mse == min(mse))

# Plot performance
svr_perf <- perf_plot(data_lists = data_svr_lists,
                      data_train = data_train_scaled %>% tail(-1),
                      data_val = data_val_scaled %>% tail(-1), 
                      hyperparams = best_tune_svr[1,],
                      fit_func = svr_fit_func,
                      type = "svr",
                      train_title = "SVR One-Day Ahead Train Plot",
                      val_title = "SVR One-Day Ahead Validation Plot")

svr_perf$training_error

svr_perf$performance
```

```{r svr_3_list}
# Create list of training and validation sets

data_svr_array_3 <- data_array_func(data = data_train_scaled,
                                  val = data_val_scaled,
                                  initial = 2,
                                  assess = 1,
                                  skip = 0, 
                                  type = "three_day")

data_svr_lists_3 <- data_svr_wrangle(data_array = data_svr_array_3)
```

```{r svr_3_eval_perf}


if(!cache){
  tic()
  svr_fit_3 <- hyp_tune_func(data_lists = data_svr_lists_3,
                         data_actual = data_val_scaled %>% tail(-4),
                         hyperparams = svr_hyp_3,
                         fit_func = svr_fit_func, 
                         type = "svr")
  write.csv(svr_fit_3, "cache/svr_tune_3")
  toc()
}

if(cache){
  svr_fit_3 <- read.csv("cache/svr_tune_3", row.names = 1) %>% as_tibble()
}

# Best hyperparameters

best_tune_svr_3 <- svr_fit_3 %>% filter(mse == min(mse))

# Plot performance
svr_perf_3 <- perf_plot(data_lists = data_svr_lists_3,
                         data_train = data_train_scaled %>% tail(-4),
                         data_val = data_val_scaled %>% tail(-4), 
                      hyperparams = best_tune_svr_3[1,],
                      fit_func = svr_fit_func,
                      type = "svr",
                      train_title = "SVR Three-Day Ahead Train Plot",
                      val_title = "SVR Three-Day Ahead Validation Plot")

svr_perf_3$training_error

svr_perf_3$performance
```

```{r plot_val_3, fig.align='center', fig.cap="SVR Three-Day Ahead Validation Forecast"}
svr_perf_3$val_plot
```


```{r test_one_day}
### Create LSTM Data Arrays
data_lstm_lists_test <- data_array_func(data = data_train_full_scaled, 
                              val = data_test_scaled,
                              initial = 1, 
                              assess = 1, 
                              skip = 0, 
                              type = "one_day")

# Fit Model and Evaluate Performance
lstm_perf_test <- perf_plot(data_lists = data_lstm_lists_test,
                       data_val = data_test_scaled %>% tail(-1), 
                       data_train = data_train_full_scaled %>% tail(-1),
                       hyperparams = best_lstm_tune,
                       fit_func = lstm_fit_func,
                       type = "lstm",
                       train_title = "LSTM One-Day Ahead Full Train Plot",
                       val_title = "LSTM One-Day Ahead Test Plot")


lstm_perf_test$training_error$mse

lstm_perf_test$performance$mse
```


```{r plot_test, fig.align='center', fig.cap="LSTM One-Day Ahead Test Forecast"}
lstm_perf_test$val_plot
```


```{r test_three_day}
# Create list of training and validation sets

data_svr_array_3_test <- data_array_func(data = data_train_full_scaled,
                                  val = data_test_scaled,
                                  initial = 2,
                                  assess = 1,
                                  skip = 0, 
                                  type = "three_day")

data_svr_lists_3_test <- data_svr_wrangle(data_array = data_svr_array_3_test)

# Plot performance
svr_perf_3_test <- perf_plot(data_lists = data_svr_lists_3_test,
                         data_train = data_train_full_scaled %>% tail(-4),
                         data_val = data_test_scaled %>% tail(-4), 
                      hyperparams = best_tune_svr_3[1,],
                      fit_func = svr_fit_func,
                      type = "svr",
                      train_title = "SVR Three-Day Ahead Full Training Plot",
                      val_title = "SVR Three-Day Ahead Test Plot")

svr_perf_3_test$training_error
svr_perf_3_test$performance
```


```{r plot_3_test, fig.align='center', fig.cap="LSTM Three-Day Ahead Test Forecast"}
svr_perf_3_test$val_plot
```

# Conclusion


\newpage

# References {-}

<div id="refs"></div>


# Appendix {-}

```{r plot_1, fig.align='center', fig.cap="EGARCH(1,1) One-Day Ahead Training Forecast"}
garch_train_plot
```

```{r plot_2, fig.align='center', fig.cap="EGARCH(1,1) One-Day Ahead Validation Forecast"}
garch_val_plot
```

```{r plot_3, fig.align='center', fig.cap="LSTM One-Day Ahead Training Forecast"}
lstm_perf$train_plot
```

```{r plot_4, fig.align='center', fig.cap="LSTM Three-Day Ahead Training Forecast"}
lstm_perf_3$train_plot
```

```{r plot_5, fig.align='center', fig.cap="SVR One-Day Ahead Training Forecast"}
svr_perf$train_plot
```

```{r plot_6, fig.align='center', fig.cap="SVR One-Day Ahead Validation Forecast"}
svr_perf$val_plot
```

```{r plot_7, fig.align='center', fig.cap="SVR Three-Day Ahead Training Forecast"}
svr_perf_3$train_plot
```

```{r plot_8, fig.align='center', fig.cap="LSTM Three-Day Ahead Validation Forecast"}
lstm_perf_3$val_plot
```

```{r plot_9, fig.align='center', fig.cap="LSTM One-Day Ahead Full Training Forecast"}
lstm_perf_test$train_plot
```

```{r plot_10, fig.align='center', fig.cap="SVR Three-Day Ahead Full Training Forecast"}
svr_perf_3_test$training_plot
```

